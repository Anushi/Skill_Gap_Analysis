# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x_AVukk7CGafAt2IbgmgJcAdrno_PuHP
"""

!pip install pandas

import pandas as pd

from google.colab import files
uploaded = files.upload()

resume_df = pd.read_csv('Resume.csv')
job_df = pd.read_csv('data job posts.csv')

print("üßæ Resume Dataset Overview")
print("-" * 30)
print("Shape:", resume_df.shape)
print("Columns:", resume_df.columns.tolist())
display(resume_df.head(3))

print("\nüíº Job Postings Dataset Overview")
print("-" * 30)
print("Shape:", job_df.shape)
print("Columns:", job_df.columns.tolist())
display(job_df.head(3))

print("\nüîç Null Values in Resume Data:")
print(resume_df.isnull().sum())

print("\nüîç Null Values in Job Postings Data:")
print(job_df.isnull().sum())

# STEP 2: Skill Extraction from Resumes and Job Descriptions

# 1Ô∏è‚É£ Install and load SpaCy
!pip install spacy
import spacy
import re
import pandas as pd

# Download English model
!python -m spacy download en_core_web_sm
nlp = spacy.load("en_core_web_sm")

# 2Ô∏è‚É£ Define a list of common skills (you can expand this)
skill_keywords = [
    "python", "java", "sql", "excel", "communication", "teamwork", "ml",
    "deep learning", "data analysis", "r", "project management", "html",
    "css", "power bi", "tableau", "machine learning", "ai", "nlp",
    "pandas", "numpy", "matplotlib", "tensorflow", "keras", "flask"
]

# 3Ô∏è‚É£ Helper: Clean and extract skills from text
def extract_skills(text):
    if pd.isnull(text):
        return []
    text = text.lower()
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    tokens = text.split()
    found = set()
    for skill in skill_keywords:
        if skill in text:
            found.add(skill)
    return list(found)

# 4Ô∏è‚É£ Extract from Resume Text
resume_df['Extracted_Skills'] = resume_df['Resume_str'].apply(extract_skills)

# 5Ô∏è‚É£ Combine JobDescription + JobRequirment for job skills
job_df['FullText'] = job_df['JobDescription'].fillna('') + ' ' + job_df['JobRequirment'].fillna('')
job_df['Extracted_JobSkills'] = job_df['FullText'].apply(extract_skills)

# 6Ô∏è‚É£ Show sample results
print("üîç Sample Resume Skills")
display(resume_df[['Resume_str', 'Extracted_Skills']].head(2))

print("üîç Sample Job Required Skills")
display(job_df[['Title', 'Extracted_JobSkills']].head(2))

# STEP 3: Skill Gap Analyzer

# 1Ô∏è‚É£ Compare skill sets
def calculate_skill_gap(resume_skills, job_skills):
    return list(set(job_skills) - set(resume_skills))

# 2Ô∏è‚É£ For simplicity, compare each resume with the first job (for now)
resume_df['Matched_Job_Title'] = job_df.loc[0, 'Title']
resume_df['Job_Required_Skills'] = [job_df.loc[0, 'Extracted_JobSkills']] * len(resume_df)
resume_df['Skill_Gap'] = resume_df.apply(lambda row: calculate_skill_gap(row['Extracted_Skills'], row['Job_Required_Skills']), axis=1)

# 3Ô∏è‚É£ Display sample output
display(resume_df[['Resume_str', 'Extracted_Skills', 'Job_Required_Skills', 'Skill_Gap']].head(2))

def calculate_skill_gap(extracted_skills, required_skills):
    # Return list of required skills that are missing in the candidate skills
    return [skill for skill in required_skills if skill not in extracted_skills]

resume_df['Job_Required_Skills'] = [job_df.loc[0, 'Extracted_JobSkills']] * len(resume_df)

resume_df['Skill_Gap'] = resume_df.apply(
    lambda row: calculate_skill_gap(row['Extracted_Skills'], row['Job_Required_Skills']),
    axis=1
)

resume_df['Missing_Skill_Count'] = resume_df['Skill_Gap'].apply(len)

sorted_resumes = resume_df.sort_values(by='Missing_Skill_Count')

print(sorted_resumes[['Resume_str', 'Extracted_Skills', 'Skill_Gap', 'Missing_Skill_Count']].head(10))

def extra_skills(extracted_skills, required_skills):
    return [skill for skill in extracted_skills if skill not in required_skills]

resume_df['Extra_Skills'] = resume_df.apply(
    lambda row: extra_skills(row['Extracted_Skills'], row['Job_Required_Skills']),
    axis=1
)

# Check candidates with most extra skills
resume_df.sort_values(by='Extra_Skills', key=lambda col: col.str.len(), ascending=False)[
    ['Resume_str', 'Extracted_Skills', 'Extra_Skills', 'Skill_Gap']
].head(10)

# Assuming you already have 'Extra_Skills' column calculated
resume_df['Extra_Skill_Count'] = resume_df['Extra_Skills'].apply(len)

filtered_resumes = resume_df[resume_df['Missing_Skill_Count'] == 0]

ranked_resumes = filtered_resumes.sort_values(by='Extra_Skill_Count', ascending=False)

# Display top 10 resumes
print(ranked_resumes[['Resume_str', 'Extra_Skill_Count', 'Skill_Gap']].head(10))

import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
plt.hist(resume_df['Extra_Skill_Count'], bins=20, color='skyblue')
plt.xlabel('Number of Extra Skills')
plt.ylabel('Number of Candidates')
plt.title('Distribution of Extra Skills Count among Candidates')
plt.show()

plt.figure(figsize=(8,5))
plt.scatter(resume_df['Missing_Skill_Count'], resume_df['Extra_Skill_Count'], alpha=0.5)
plt.xlabel('Number of Missing Skills')
plt.ylabel('Number of Extra Skills')
plt.title('Candidates: Missing Skills vs Extra Skills')
plt.show()

def calculate_skill_gap(resume_skills, job_skills):
    """
    Returns the list of skills required by the job but missing in the resume.
    """
    return [skill for skill in job_skills if skill not in resume_skills]

# Example 1: Candidate missing one skill 'python'
resume_1 = ['ai', 'r']
job_1 = ['ai', 'r', 'python']
gap_1 = calculate_skill_gap(resume_1, job_1)
print("Test 1 - Missing skills:", gap_1)  # Expected output: ['python']

# Example 2: Candidate has all required skills
resume_2 = ['ai', 'r', 'python']
job_2 = ['ai', 'r']
gap_2 = calculate_skill_gap(resume_2, job_2)
print("Test 2 - Missing skills:", gap_2)  # Expected output: []

print("Job Required Skills:", job_1)

# New job requirements with more specific skills
job_advanced = ['ai', 'r', 'python', 'machine learning', 'deep learning', 'data analysis']

# Candidate with partial skills
resume_advanced = ['ai', 'r', 'python']

gap_advanced = calculate_skill_gap(resume_advanced, job_advanced)
print("Test 3 - Missing skills:", gap_advanced)
# Expected output: ['machine learning', 'deep learning', 'data analysis']

# Apply skill gap calculation row-wise (example for one job)
resume_df['Skill_Gap'] = resume_df.apply(
    lambda row: calculate_skill_gap(row['Extracted_Skills'], row['Job_Required_Skills']),
    axis=1
)

# Check the first 5 rows of skill gaps
print(resume_df[['Extracted_Skills', 'Job_Required_Skills', 'Skill_Gap']].head())

print("Job Required Skills:", job_df.loc[0, 'Extracted_JobSkills'])

job_skills = ['ai', 'r', 'python', 'machine learning', 'data analysis', 'sql']

def calculate_skill_gap(resume_skills, job_skills):
    # Use set difference for speed and uniqueness
    return list(set(job_skills) - set(resume_skills))

resume_df['Skill_Gap'] = resume_df.apply(
    lambda row: calculate_skill_gap(row['Extracted_Skills'], job_skills),
    axis=1
)

print(calculate_skill_gap(['ai', 'r'], ['ai', 'r', 'python', 'sql']))
# Expected: ['python', 'sql']

print(calculate_skill_gap(['ai', 'r', 'python'], ['ai', 'r', 'python']))
# Expected: []

resume_df['Missing_Skill_Count'] = resume_df['Skill_Gap'].apply(len)
print(resume_df['Missing_Skill_Count'].value_counts())

strict_job_skills = ['python', 'java', 'sql', 'cloud computing', 'docker', 'kubernetes']

resume_df['Skill_Gap'] = resume_df.apply(
    lambda row: calculate_skill_gap(row['Extracted_Skills'], strict_job_skills),
    axis=1
)

print(resume_df[['Extracted_Skills', 'Skill_Gap']].head(10))

# Count missing job-required skills
resume_df['Missing_Skill_Count'] = resume_df['Skill_Gap'].apply(len)

# Compare to job skills to find extras (not required, but possessed)
def get_extra_skills(resume_skills, job_skills):
    return list(set(resume_skills) - set(job_skills))

job_required_skills = ['python', 'java', 'sql', 'cloud computing', 'docker', 'kubernetes']
resume_df['Extra_Skills'] = resume_df['Extracted_Skills'].apply(
    lambda x: get_extra_skills(x, job_required_skills)
)

# Count extra skills
resume_df['Extra_Skill_Count'] = resume_df['Extra_Skills'].apply(len)

ranked = resume_df.sort_values(by=['Missing_Skill_Count', 'Extra_Skill_Count'], ascending=[True, False])
print(ranked[['Extracted_Skills', 'Skill_Gap', 'Missing_Skill_Count', 'Extra_Skills', 'Extra_Skill_Count']].head(10))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,5))
sns.histplot(resume_df['Missing_Skill_Count'], bins=range(0, max(resume_df['Missing_Skill_Count'])+2), kde=False)
plt.title("Distribution of Missing Job Skills Across Resumes")
plt.xlabel("Number of Missing Job Skills")
plt.ylabel("Number of Candidates")
plt.grid(True)
plt.show()

# Example: candidates missing 0 or 1 skill
best_candidates = resume_df[resume_df['Missing_Skill_Count'] <= 1]
print(best_candidates[['Extracted_Skills', 'Skill_Gap', 'Extra_Skills']])

job_required_skills = ['python', 'java', 'sql', 'cloud computing', 'docker', 'kubernetes']

print(resume_df['Missing_Skill_Count'].value_counts().sort_index())

# Candidates missing 3 or fewer skills
best_candidates = resume_df[resume_df['Missing_Skill_Count'] <= 3]
print(best_candidates[['Extracted_Skills', 'Skill_Gap', 'Extra_Skills']])

ranked = resume_df.sort_values(by=['Missing_Skill_Count', 'Extra_Skill_Count'], ascending=[True, False])
print(ranked[['Extracted_Skills', 'Skill_Gap', 'Missing_Skill_Count', 'Extra_Skills', 'Extra_Skill_Count']].head(10))

top_candidates = ranked.head(10)
print(top_candidates[['Extracted_Skills', 'Skill_Gap', 'Missing_Skill_Count', 'Extra_Skills', 'Extra_Skill_Count']])

import matplotlib.pyplot as plt

resume_df['Missing_Skill_Count'].value_counts().sort_index().plot(kind='bar')
plt.xlabel('Number of Missing Skills')
plt.ylabel('Number of Candidates')
plt.title('Distribution of Skill Gaps')
plt.grid(axis='y')
plt.show()

top_candidates.to_csv("top_skill_gap_candidates.csv", index=False)

true_skills_dict = {
    1: ['python', 'sql', 'ml'],
    2: ['java', 'excel', 'cloud computing'],
    3: ['ai', 'r', 'communication']
}

from sklearn.metrics import precision_score, recall_score, f1_score

def evaluate_skill_extraction(resume_id, extracted_skills, true_skills_dict):
    true = set(true_skills_dict[resume_id])
    pred = set(extracted_skills)

    tp = len(true & pred)
    fp = len(pred - true)
    fn = len(true - pred)

    precision = tp / (tp + fp) if (tp + fp) else 0
    recall = tp / (tp + fn) if (tp + fn) else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0

    return precision, recall, f1

resume_id = 1
extracted = ['python', 'sql', 'ml', 'html']
evaluate_skill_extraction(resume_id, extracted, true_skills_dict)

total_p, total_r, total_f1 = 0, 0, 0
n = len(true_skills_dict)

for resume_id in true_skills_dict:
    extracted = resume_df.loc[resume_id, 'Extracted_Skills']
    p, r, f1 = evaluate_skill_extraction(resume_id, extracted, true_skills_dict)
    total_p += p
    total_r += r
    total_f1 += f1

avg_p = total_p / n
avg_r = total_r / n
avg_f1 = total_f1 / n

print(f"Avg Precision: {avg_p:.2f}, Recall: {avg_r:.2f}, F1-score: {avg_f1:.2f}")

skill_set = set([
    'python', 'java', 'r', 'sql', 'excel', 'ml', 'ai', 'html', 'css', 'pandas', 'numpy',
    'tensorflow', 'deep learning', 'nlp', 'cloud computing', 'docker', 'kubernetes',
    'power bi', 'tableau', 'project management', 'communication', 'teamwork',
    'data analysis', 'matplotlib'
])

import re

def normalize(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    return text

def extract_skills(text, skill_set):
    text = normalize(text)
    return [skill for skill in skill_set if skill in text]

ground_truth_skills = {
    0: ['ai', 'r', 'data analysis'],
    1: ['ai', 'project management', 'r', 'communication'],
    2: ['ml', 'excel', 'ai', 'r', 'project management'],
    3: ['ml', 'excel', 'ai', 'r', 'communication'],
    4: ['ml', 'excel', 'ai', 'teamwork', 'r', 'project management'],
    5: ['excel', 'r', 'ai'],
    6: ['ml', 'ai', 'r', 'project management'],
    7: ['ml', 'ai', 'r', 'project management', 'communication'],
    8: ['excel', 'ai', 'r', 'project management', 'communication'],
    9: ['ai', 'r'],
    10: ['python', 'r', 'sql', 'ml'],
    11: ['excel', 'power bi', 'communication'],
    12: ['html', 'css', 'python', 'java'],
    13: ['cloud computing', 'docker', 'kubernetes'],
    14: ['ai', 'project management', 'teamwork'],
    15: ['pandas', 'numpy', 'matplotlib', 'ml'],
    16: ['excel', 'sql', 'communication'],
    17: ['data analysis', 'python', 'r'],
    18: ['html', 'css', 'project management'],
    19: ['power bi', 'tableau', 'ai']
}

from sklearn.metrics import precision_score, recall_score, f1_score

# Example evaluation
y_true = [['python', 'sql'], ['ml']]
y_pred = [['python', 'java'], ['ml', 'excel']]

def evaluate(y_true, y_pred):
    y_true_flat = [skill for sublist in y_true for skill in sublist]
    y_pred_flat = [skill for sublist in y_pred for skill in sublist]
    y_true_bin = [1 if skill in y_true_flat else 0 for skill in skill_set]
    y_pred_bin = [1 if skill in y_pred_flat else 0 for skill in skill_set]

    precision = precision_score(y_true_bin, y_pred_bin)
    recall = recall_score(y_true_bin, y_pred_bin)
    f1 = f1_score(y_true_bin, y_pred_bin)

    return precision, recall, f1

evaluate(y_true, y_pred)

precision, recall, f1 = evaluate(y_true, y_pred)
print(f"Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}")

!pip install spacy sentence-transformers sklearn

import spacy

nlp = spacy.load('en_core_web_sm')

def preprocess(text):
    doc = nlp(text.lower())
    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]
    return tokens

# Example skill dictionary with synonyms
skill_dict = {
    "machine learning": ["ml", "machine learning", "machine-learning"],
    "python": ["python", "py"],
    "project management": ["project management", "pm"],
    "sql": ["sql", "structured query language"],
    "cloud computing": ["cloud computing", "aws", "azure", "gcp"],
    "docker": ["docker", "containers"],
    "kubernetes": ["kubernetes", "k8s"],
    # Add more skills & synonyms here
}

# Flatten synonyms to skill map for quick lookup
synonym_to_skill = {}
for skill, synonyms in skill_dict.items():
    for syn in synonyms:
        synonym_to_skill[syn] = skill

def extract_skills_keyword(text):
    tokens = preprocess(text)
    extracted_skills = set()
    for token in tokens:
        if token in synonym_to_skill:
            extracted_skills.add(synonym_to_skill[token])
    return list(extracted_skills)

def extract_skills_ner(text):
    doc = nlp(text)
    skills = set()
    for ent in doc.ents:
        # Basic heuristic: filter entities of type ORG, PRODUCT, or WORK_OF_ART as skills (for demo)
        if ent.label_ in ['ORG', 'PRODUCT', 'WORK_OF_ART']:
            skills.add(ent.text.lower())
    return list(skills)

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('all-MiniLM-L6-v2')

# Prepare skill embeddings
skills_list = list(skill_dict.keys())
skill_embeddings = model.encode(skills_list, convert_to_tensor=True)

def extract_skills_semantic(text, threshold=0.6):
    embeddings = model.encode([text], convert_to_tensor=True)
    cos_scores = util.pytorch_cos_sim(embeddings, skill_embeddings)[0]
    matched_skills = []
    for i, score in enumerate(cos_scores):
        if score > threshold:
            matched_skills.append(skills_list[i])
    return matched_skills

def extract_skills(text):
    skills_keyword = set(extract_skills_keyword(text))
    skills_ner = set(extract_skills_ner(text))
    skills_semantic = set(extract_skills_semantic(text))
    combined = skills_keyword.union(skills_ner).union(skills_semantic)
    return list(combined)

def calculate_skill_gap(resume_skills, job_skills):
    return [skill for skill in job_skills if skill not in resume_skills]

from sklearn.metrics import precision_score, recall_score, f1_score

def evaluate_extraction(y_true_list, y_pred_list, skill_set):
    # y_true_list and y_pred_list are list of skills for each resume
    # Create binary vectors for each resume over the skill set
    skill_to_idx = {skill: i for i, skill in enumerate(skill_set)}

    def vectorize(skills):
        vec = [0]*len(skill_set)
        for s in skills:
            if s in skill_to_idx:
                vec[skill_to_idx[s]] = 1
        return vec

    y_true_vecs = [vectorize(skills) for skills in y_true_list]
    y_pred_vecs = [vectorize(skills) for skills in y_pred_list]

    y_true_flat = [item for sublist in y_true_vecs for item in sublist]
    y_pred_flat = [item for sublist in y_pred_vecs for item in sublist]

    precision = precision_score(y_true_flat, y_pred_flat)
    recall = recall_score(y_true_flat, y_pred_flat)
    f1 = f1_score(y_true_flat, y_pred_flat)
    return precision, recall, f1

# Sample job required skills (expand this for your domain)
job_required_skills = [
    "machine learning", "python", "project management", "sql",
    "cloud computing", "docker", "kubernetes"
]

# Sample resumes and their ground truth skills
resumes = [
    "Experienced in python, ml and project management using cloud computing",
    "Skilled in sql, docker and managing projects",
    "Expertise in kubernetes and python programming",
]

ground_truth = [
    ["python", "machine learning", "project management", "cloud computing"],
    ["sql", "docker", "project management"],
    ["kubernetes", "python"],
]

for i, resume_text in enumerate(resumes):
    extracted = extract_skills(resume_text)
    skill_gap = calculate_skill_gap(extracted, job_required_skills)
    print(f"Resume {i+1} Extracted Skills: {extracted}")
    print(f"Skill Gap: {skill_gap}")

# Evaluate
precision, recall, f1 = evaluate_extraction(ground_truth, [extract_skills(r) for r in resumes], job_required_skills)
print(f"\nEvaluation:\nPrecision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}")